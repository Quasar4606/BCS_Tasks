{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2fac094-bc9c-4992-b2a1-8655cac1d4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter mass of body 1 (in kg):  2\n",
      "Enter mass of body 2 (in kg):  3\n",
      "Enter the initial x-coordinate of the body 1(in m):  2\n",
      "Enter the initial y-coordinate of the body 1(in m):  1\n",
      "Enter the initial x-coordinate of the body 2(in m):  4\n",
      "Enter the initial y-coordinate of the body 2(in m):  2\n",
      "Enter the initial x-velocity of the body 1 (in m/s):  2\n",
      "Enter the initial y-velocity of the body 1(in m/s):  5\n",
      "Enter the initial x-velocity of the body 2(in m/s):  2\n",
      "Enter the initial y-velocity of the body 2(in m/s):  3\n",
      "Enter the time for prediction (seconds):  15\n"
     ]
    }
   ],
   "source": [
    "#Dance of the Planets\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "G = 6.67430e-11 #Gravitational constant(m^3 kg^-1 s^-2)\n",
    "\n",
    "#things the user will provide\n",
    "\n",
    "m_1 = float(input(\"Enter mass of body 1 (in kg): \"))\n",
    "m_2 = float(input(\"Enter mass of body 2 (in kg): \"))\n",
    "x_1_0 = np.array([float(input(\"Enter the initial x-coordinate of the body 1(in m): \")), \n",
    "               float(input(\"Enter the initial y-coordinate of the body 1(in m): \"))])\n",
    "\n",
    "x_2_0 = np.array([float(input(\"Enter the initial x-coordinate of the body 2(in m): \")), \n",
    "               float(input(\"Enter the initial y-coordinate of the body 2(in m): \"))])\n",
    "v_1_0 = np.array([float(input(\"Enter the initial x-velocity of the body 1 (in m/s): \")), \n",
    "               float(input(\"Enter the initial y-velocity of the body 1(in m/s): \"))])\n",
    "\n",
    "v_2_0 = np.array([float(input(\"Enter the initial x-velocity of the body 2(in m/s): \")), \n",
    "               float(input(\"Enter the initial y-velocity of the body 2(in m/s): \"))])\n",
    "t = float(input(\"Enter the time for prediction (seconds): \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3fa4849-81fc-42da-bab6-158ee972a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating coordinates at T using ODE solvers\n",
    "#I will use odeint for solving this\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "#we need to define 2 functions for it\n",
    "\n",
    "def two_body_ode(y, t, G, m1, m2): #defines the system of ODE which odeint will solve\n",
    "    # y contains: x1_x, x1_y, v1_x, v1_y, x2_x, x2_y, v2_x, v2_y\n",
    "    x1 = y[0:2]\n",
    "    v1 = y[2:4]\n",
    "    x2 = y[4:6]\n",
    "    v2 = y[6:8]\n",
    "\n",
    "    r = x2 - x1            # vector from body 1 to body 2\n",
    "    dist_cubed = np.linalg.norm(r)**3\n",
    "\n",
    "    dx1_dt = v1\n",
    "    dv1_dt = G * m2 * r / dist_cubed\n",
    "    dx2_dt = v2\n",
    "    dv2_dt = G * m1 * (-r) / dist_cubed\n",
    "\n",
    "    return np.concatenate([dx1_dt, dv1_dt, dx2_dt, dv2_dt])\n",
    "\n",
    "def get_coordinates_at_t(t, y0, G, m1, m2): #uses odeint to integrate the ode over the specified time t\n",
    "    t_interval = [0, t]\n",
    "    sol = odeint(two_body_ode, y0, t_interval, args=(G, m1, m2))\n",
    "    return sol[-1]  # returns an array of length 8\n",
    "\n",
    "y0 = np.concatenate([x_1_0, v_1_0, x_2_0, v_2_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cfba874-d17b-4ac7-b00c-a989b9463319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>v_1_x</th>\n",
       "      <th>v_1_y</th>\n",
       "      <th>v_2_x</th>\n",
       "      <th>v_2_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.075</td>\n",
       "      <td>4.03</td>\n",
       "      <td>2.045</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.150</td>\n",
       "      <td>4.06</td>\n",
       "      <td>2.090</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.225</td>\n",
       "      <td>4.09</td>\n",
       "      <td>2.135</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.300</td>\n",
       "      <td>4.12</td>\n",
       "      <td>2.180</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>14.925</td>\n",
       "      <td>31.85</td>\n",
       "      <td>75.625</td>\n",
       "      <td>33.85</td>\n",
       "      <td>46.775</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>14.940</td>\n",
       "      <td>31.88</td>\n",
       "      <td>75.700</td>\n",
       "      <td>33.88</td>\n",
       "      <td>46.820</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>14.955</td>\n",
       "      <td>31.91</td>\n",
       "      <td>75.775</td>\n",
       "      <td>33.91</td>\n",
       "      <td>46.865</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>14.970</td>\n",
       "      <td>31.94</td>\n",
       "      <td>75.850</td>\n",
       "      <td>33.94</td>\n",
       "      <td>46.910</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>14.985</td>\n",
       "      <td>31.97</td>\n",
       "      <td>75.925</td>\n",
       "      <td>33.97</td>\n",
       "      <td>46.955</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          T    x_1     y_1    x_2     y_2  v_1_x  v_1_y  v_2_x  v_2_y\n",
       "0     0.000   2.00   1.000   4.00   2.000    2.0    5.0    2.0    3.0\n",
       "1     0.015   2.03   1.075   4.03   2.045    2.0    5.0    2.0    3.0\n",
       "2     0.030   2.06   1.150   4.06   2.090    2.0    5.0    2.0    3.0\n",
       "3     0.045   2.09   1.225   4.09   2.135    2.0    5.0    2.0    3.0\n",
       "4     0.060   2.12   1.300   4.12   2.180    2.0    5.0    2.0    3.0\n",
       "..      ...    ...     ...    ...     ...    ...    ...    ...    ...\n",
       "995  14.925  31.85  75.625  33.85  46.775    2.0    5.0    2.0    3.0\n",
       "996  14.940  31.88  75.700  33.88  46.820    2.0    5.0    2.0    3.0\n",
       "997  14.955  31.91  75.775  33.91  46.865    2.0    5.0    2.0    3.0\n",
       "998  14.970  31.94  75.850  33.94  46.910    2.0    5.0    2.0    3.0\n",
       "999  14.985  31.97  75.925  33.97  46.955    2.0    5.0    2.0    3.0\n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset generation\n",
    "import pandas as pd\n",
    "#for generating dataset I need to find the values at different times.\n",
    "#for solving ODE I have used odeint.\n",
    "no_points = 1000 # let dataset have 10000 points\n",
    "dt = t/no_points # formula for finding dt\n",
    "\n",
    "#lists for storing data for DataFrame\n",
    "time_T = []\n",
    "x_1 = []\n",
    "y_1 = []\n",
    "x_2 = []\n",
    "y_2 = []\n",
    "v_1_x = []\n",
    "v_1_y = []\n",
    "v_2_x = []\n",
    "v_2_y = []\n",
    "\n",
    "#making variable for loop\n",
    "time_current = 0\n",
    "\n",
    "while time_current < t :\n",
    "    result = get_coordinates_at_t(time_current, y0, G, m_1, m_2)\n",
    "    x_1_current, v_1_current, x_2_current, v_2_current = result[0:2], result[2:4], result[4:6], result[6:8]\n",
    "    \n",
    "\n",
    "    #store the data using .append()\n",
    "    time_T.append(time_current)\n",
    "    x_1.append(x_1_current[0])\n",
    "    y_1.append(x_1_current[1])\n",
    "    x_2.append(x_2_current[0])\n",
    "    y_2.append(x_2_current[1])\n",
    "    v_1_x.append(v_1_current[0])\n",
    "    v_1_y.append(v_1_current[1])\n",
    "    v_2_x.append(v_2_current[0])\n",
    "    v_2_y.append(v_2_current[1])\n",
    "\n",
    "    time_current += dt #update the time to be not stuck in infinite loop\n",
    "\n",
    "#create dataframe\n",
    "data = pd.DataFrame({\n",
    "    'T': time_T,\n",
    "    'x_1': x_1,\n",
    "    'y_1': y_1,\n",
    "    'x_2': x_2,\n",
    "    'y_2': y_2,\n",
    "    'v_1_x': v_1_x,\n",
    "    'v_1_y': v_1_y,\n",
    "    'v_2_x': v_2_x,\n",
    "    'v_2_y': v_2_y\n",
    "})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f2ab314-3d95-441d-b2b0-f738088105d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.075</td>\n",
       "      <td>4.03</td>\n",
       "      <td>2.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.150</td>\n",
       "      <td>4.06</td>\n",
       "      <td>2.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.225</td>\n",
       "      <td>4.09</td>\n",
       "      <td>2.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.300</td>\n",
       "      <td>4.12</td>\n",
       "      <td>2.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>14.925</td>\n",
       "      <td>31.85</td>\n",
       "      <td>75.625</td>\n",
       "      <td>33.85</td>\n",
       "      <td>46.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>14.940</td>\n",
       "      <td>31.88</td>\n",
       "      <td>75.700</td>\n",
       "      <td>33.88</td>\n",
       "      <td>46.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>14.955</td>\n",
       "      <td>31.91</td>\n",
       "      <td>75.775</td>\n",
       "      <td>33.91</td>\n",
       "      <td>46.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>14.970</td>\n",
       "      <td>31.94</td>\n",
       "      <td>75.850</td>\n",
       "      <td>33.94</td>\n",
       "      <td>46.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>14.985</td>\n",
       "      <td>31.97</td>\n",
       "      <td>75.925</td>\n",
       "      <td>33.97</td>\n",
       "      <td>46.955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          T    x_1     y_1    x_2     y_2\n",
       "0     0.000   2.00   1.000   4.00   2.000\n",
       "1     0.015   2.03   1.075   4.03   2.045\n",
       "2     0.030   2.06   1.150   4.06   2.090\n",
       "3     0.045   2.09   1.225   4.09   2.135\n",
       "4     0.060   2.12   1.300   4.12   2.180\n",
       "..      ...    ...     ...    ...     ...\n",
       "995  14.925  31.85  75.625  33.85  46.775\n",
       "996  14.940  31.88  75.700  33.88  46.820\n",
       "997  14.955  31.91  75.775  33.91  46.865\n",
       "998  14.970  31.94  75.850  33.94  46.910\n",
       "999  14.985  31.97  75.925  33.97  46.955\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as we only need to predict x_1, y_1, x_2 and y_2 we can drop v_1_x, v_1_y, v_2_x and v_2_y\n",
    "\n",
    "data = data.drop( [\"v_1_x\", \"v_1_y\", \"v_2_x\", \"v_2_y\"], axis = 1) #code to drop columns \n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "data.to_csv('data.csv', index=False)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c538e898-34a1-412c-8563-d5e9effd5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "\n",
    "#as this has input only as time I'm not using train_test_split as it might lead to data leakage, instead I'm manually splitting the data\n",
    "#could use TimeSeriesSplit as well\n",
    "#refer source - https://tomerkatzav.medium.com/split-time-series-dataset-826b7dc39cd9\n",
    "train_data_size = int(len(data)*0.7) #spliiting such that 70% is train data, 15% is validation data and rest is test data\n",
    "val_data_size = int(len(data)*0.15)\n",
    "\n",
    "train_data = data.iloc[ :train_data_size, :] #splitting\n",
    "val_data = data.iloc[train_data_size:train_data_size + val_data_size, :]\n",
    "test_data = data.iloc[train_data_size + val_data_size:, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e9d25ac-0dd5-456f-b9cb-db1d303e13f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting in numpy\n",
    "train_data = train_data.values \n",
    "val_data = val_data.values\n",
    "test_data = test_data.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8600de29-9e88-41ab-a68b-910bf467814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating neural model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional  as F\n",
    "\n",
    "class NN(nn.Module) :\n",
    "    def __init__(self):\n",
    "        super().__init__()   #this is how u write constructor in python \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(1,128),  #1 input layer\n",
    "            nn.Tanh(),  #using a smooth activation function\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64,64),  #3 hidden layers activated with tanh as its smooth and differentiable\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64,4)   #4 output layers\n",
    "        )\n",
    "\n",
    "    def forward(self,T) :\n",
    "        return self.layers(T)\n",
    "\n",
    "model = NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7daca57c-67ca-4386-90b9-d37058da979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now first I need to convert the data into Pytorch tensors\n",
    "train_data_tensor = torch.FloatTensor(train_data) \n",
    "val_data_tensor= torch.FloatTensor(val_data)\n",
    "test_data_tensor = torch.FloatTensor(test_data)\n",
    "\n",
    "loss_fn = F.mse_loss # defining loss function\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr = 1e-3) #using Adam(Adaptive Moment Estimation) optimizer as it \n",
    "                                                       #converges quickly and is widely used in deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30cccc2c-c8cb-4843-b36a-a17e28241724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this I will calculate ode residuals and ode loss\n",
    "def ode_loss_fn(pred_denorm,t,m_1,m_2,G):\n",
    "   \n",
    "    #splitting\n",
    "    x1_pred = pred_denorm[:,:2]\n",
    "    x2_pred = pred_denorm[:,2:]\n",
    "    if not t.requires_grad:\n",
    "        t = t.requires_grad_(True) #enables to compute derivatives w.r.t. time\n",
    "\n",
    "\n",
    "    \n",
    "    #derived velocities\n",
    "    v1_derived = torch.autograd.grad(x1_pred,t,grad_outputs=torch.ones_like(x1_pred),create_graph = True)[0] #this returns a tupple so I used [0] to get velocity\n",
    "    v2_derived = torch.autograd.grad(x2_pred,t,grad_outputs=torch.ones_like(x1_pred),create_graph = True)[0]\n",
    "\n",
    "    #derived accelerations\n",
    "    a1_derived = torch.autograd.grad(v1_derived,t,grad_outputs=torch.ones_like(v1_derived),create_graph = True)[0]\n",
    "    a2_derived = torch.autograd.grad(v2_derived,t,grad_outputs=torch.ones_like(v2_derived),create_graph = True)[0]\n",
    "\n",
    "    #predicted relative poition between them \n",
    "    r = x2_pred - x1_pred\n",
    "    r_mod = torch.norm(r,dim=1,keepdim = True)\n",
    "\n",
    "    r_cube = r_mod**3 #cube\n",
    "\n",
    "    #predicted acceleration\n",
    "    a1_pred = G*m_2*r/r_cube\n",
    "    a2_pred = G*m_1*(-r)/r_cube\n",
    "\n",
    "    #residuals\n",
    "    residual_1 = a1_derived - a1_pred\n",
    "    residual_2 = a2_derived - a2_pred\n",
    "\n",
    "    ode_loss = residual_1.pow(2).mean() + residual_2.pow(2).mean() #ode loss\n",
    "\n",
    "    mean_ode_residual = (residual_1.norm(dim = 1).mean() + residual_2.norm(dim = 1).mean())/2 #mean ode residual\n",
    "\n",
    "    return ode_loss,mean_ode_residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c935fa4-df57-40a9-ad72-fed19da9f5d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1500], Loss : 621.1776\n",
      "Epoch [10/1500], Loss : 588.5578\n",
      "Epoch [20/1500], Loss : 560.1760\n",
      "Epoch [30/1500], Loss : 534.8855\n",
      "Epoch [40/1500], Loss : 510.8741\n",
      "Epoch [50/1500], Loss : 489.5933\n",
      "Epoch [60/1500], Loss : 470.3182\n",
      "Epoch [70/1500], Loss : 452.6034\n",
      "Epoch [80/1500], Loss : 436.1937\n",
      "Epoch [90/1500], Loss : 420.9111\n",
      "Epoch [100/1500], Loss : 406.6222\n",
      "Epoch [110/1500], Loss : 393.2247\n",
      "Epoch [120/1500], Loss : 380.6378\n",
      "Epoch [130/1500], Loss : 368.7957\n",
      "Epoch [140/1500], Loss : 357.6434\n",
      "Epoch [150/1500], Loss : 347.1334\n",
      "Epoch [160/1500], Loss : 337.2239\n",
      "Epoch [170/1500], Loss : 327.8777\n",
      "Epoch [180/1500], Loss : 319.0620\n",
      "Epoch [190/1500], Loss : 310.7630\n",
      "Epoch [200/1500], Loss : 302.6259\n",
      "Epoch [210/1500], Loss : 293.8206\n",
      "Epoch [220/1500], Loss : 284.9972\n",
      "Epoch [230/1500], Loss : 276.4988\n",
      "Epoch [240/1500], Loss : 268.3252\n",
      "Epoch [250/1500], Loss : 260.4834\n",
      "Epoch [260/1500], Loss : 252.9632\n",
      "Epoch [270/1500], Loss : 245.7520\n",
      "Epoch [280/1500], Loss : 238.8363\n",
      "Epoch [290/1500], Loss : 232.2005\n",
      "Epoch [300/1500], Loss : 225.8280\n",
      "Epoch [310/1500], Loss : 219.7042\n",
      "Epoch [320/1500], Loss : 213.8159\n",
      "Epoch [330/1500], Loss : 208.1511\n",
      "Epoch [340/1500], Loss : 202.6984\n",
      "Epoch [350/1500], Loss : 197.4473\n",
      "Epoch [360/1500], Loss : 192.3881\n",
      "Epoch [370/1500], Loss : 187.5114\n",
      "Epoch [380/1500], Loss : 182.8084\n",
      "Epoch [390/1500], Loss : 178.2710\n",
      "Epoch [400/1500], Loss : 173.8915\n",
      "Epoch [410/1500], Loss : 169.6623\n",
      "Epoch [420/1500], Loss : 165.5765\n",
      "Epoch [430/1500], Loss : 161.6274\n",
      "Epoch [440/1500], Loss : 157.8089\n",
      "Epoch [450/1500], Loss : 154.1151\n",
      "Epoch [460/1500], Loss : 150.5407\n",
      "Epoch [470/1500], Loss : 147.0808\n",
      "Epoch [480/1500], Loss : 143.7312\n",
      "Epoch [490/1500], Loss : 140.4880\n",
      "Epoch [500/1500], Loss : 137.3471\n",
      "Epoch [510/1500], Loss : 134.3047\n",
      "Epoch [520/1500], Loss : 131.3567\n",
      "Epoch [530/1500], Loss : 128.4993\n",
      "Epoch [540/1500], Loss : 125.7286\n",
      "Epoch [550/1500], Loss : 123.0412\n",
      "Epoch [560/1500], Loss : 120.4336\n",
      "Epoch [570/1500], Loss : 117.9027\n",
      "Epoch [580/1500], Loss : 115.4460\n",
      "Epoch [590/1500], Loss : 113.0607\n",
      "Epoch [600/1500], Loss : 110.7444\n",
      "Epoch [610/1500], Loss : 108.4948\n",
      "Epoch [620/1500], Loss : 106.3095\n",
      "Epoch [630/1500], Loss : 104.1858\n",
      "Epoch [640/1500], Loss : 102.1205\n",
      "Epoch [650/1500], Loss : 100.1118\n",
      "Epoch [660/1500], Loss : 98.1583\n",
      "Epoch [670/1500], Loss : 96.2585\n",
      "Epoch [680/1500], Loss : 94.4107\n",
      "Epoch [690/1500], Loss : 92.6130\n",
      "Epoch [700/1500], Loss : 90.8636\n",
      "Epoch [710/1500], Loss : 89.1609\n",
      "Epoch [720/1500], Loss : 87.5033\n",
      "Epoch [730/1500], Loss : 85.8894\n",
      "Epoch [740/1500], Loss : 84.3178\n",
      "Epoch [750/1500], Loss : 82.7870\n",
      "Epoch [760/1500], Loss : 81.2959\n",
      "Epoch [770/1500], Loss : 79.8430\n",
      "Epoch [780/1500], Loss : 78.4273\n",
      "Epoch [790/1500], Loss : 77.0475\n",
      "Epoch [800/1500], Loss : 75.7029\n",
      "Epoch [810/1500], Loss : 74.3919\n",
      "Epoch [820/1500], Loss : 73.1134\n",
      "Epoch [830/1500], Loss : 71.8665\n",
      "Epoch [840/1500], Loss : 70.6501\n",
      "Epoch [850/1500], Loss : 69.4634\n",
      "Epoch [860/1500], Loss : 68.3055\n",
      "Epoch [870/1500], Loss : 67.1756\n",
      "Epoch [880/1500], Loss : 66.0728\n",
      "Epoch [890/1500], Loss : 64.9963\n",
      "Epoch [900/1500], Loss : 63.9454\n",
      "Epoch [910/1500], Loss : 62.9192\n",
      "Epoch [920/1500], Loss : 61.9171\n",
      "Epoch [930/1500], Loss : 60.9385\n",
      "Epoch [940/1500], Loss : 59.9827\n",
      "Epoch [950/1500], Loss : 59.0494\n",
      "Epoch [960/1500], Loss : 58.1358\n",
      "Epoch [970/1500], Loss : 57.2401\n",
      "Epoch [980/1500], Loss : 56.3754\n",
      "Epoch [990/1500], Loss : 55.5167\n",
      "Epoch [1000/1500], Loss : 54.6880\n",
      "Epoch [1010/1500], Loss : 53.8772\n",
      "Epoch [1020/1500], Loss : 53.0831\n",
      "Epoch [1030/1500], Loss : 52.3105\n",
      "Epoch [1040/1500], Loss : 51.5627\n",
      "Epoch [1050/1500], Loss : 50.8316\n",
      "Epoch [1060/1500], Loss : 50.0699\n",
      "Epoch [1070/1500], Loss : 49.3114\n",
      "Epoch [1080/1500], Loss : 48.7651\n",
      "Epoch [1090/1500], Loss : 48.2010\n",
      "Epoch [1100/1500], Loss : 47.5944\n",
      "Epoch [1110/1500], Loss : 46.6960\n",
      "Epoch [1120/1500], Loss : 45.7659\n",
      "Epoch [1130/1500], Loss : 46.5980\n",
      "Epoch [1140/1500], Loss : 45.1786\n",
      "Epoch [1150/1500], Loss : 44.1855\n",
      "Epoch [1160/1500], Loss : 43.9402\n",
      "Epoch [1170/1500], Loss : 43.2619\n",
      "Epoch [1180/1500], Loss : 43.5484\n",
      "Epoch [1190/1500], Loss : 42.8865\n",
      "Epoch [1200/1500], Loss : 41.6081\n",
      "Epoch [1210/1500], Loss : 39.6821\n",
      "Epoch [1220/1500], Loss : 39.7346\n",
      "Epoch [1230/1500], Loss : 38.9125\n",
      "Epoch [1240/1500], Loss : 38.4123\n",
      "Epoch [1250/1500], Loss : 38.0640\n",
      "Epoch [1260/1500], Loss : 37.9048\n",
      "Epoch [1270/1500], Loss : 37.8381\n",
      "Epoch [1280/1500], Loss : 37.6994\n",
      "Epoch [1290/1500], Loss : 37.6608\n",
      "Epoch [1300/1500], Loss : 37.4673\n",
      "Epoch [1310/1500], Loss : 37.3370\n",
      "Epoch [1320/1500], Loss : 37.2557\n",
      "Epoch [1330/1500], Loss : 37.2319\n",
      "Epoch [1340/1500], Loss : 37.2772\n",
      "Epoch [1350/1500], Loss : 37.3518\n",
      "Epoch [1360/1500], Loss : 37.4694\n",
      "Epoch [1370/1500], Loss : 37.4230\n",
      "Epoch [1380/1500], Loss : 37.8050\n",
      "Epoch [1390/1500], Loss : 37.8163\n",
      "Epoch [1400/1500], Loss : 37.8310\n",
      "Epoch [1410/1500], Loss : 31.6778\n",
      "Epoch [1420/1500], Loss : 30.3775\n",
      "Epoch [1430/1500], Loss : 29.9715\n",
      "Epoch [1440/1500], Loss : 30.8322\n",
      "Epoch [1450/1500], Loss : 30.8485\n",
      "Epoch [1460/1500], Loss : 30.9551\n",
      "Epoch [1470/1500], Loss : 30.8039\n",
      "Epoch [1480/1500], Loss : 31.1952\n",
      "Epoch [1490/1500], Loss : 31.4209\n",
      "Epoch [1500/1500], Loss : 31.4520\n"
     ]
    }
   ],
   "source": [
    "#training of the data\n",
    "no_epochs = 1500 #lets keep it 200\n",
    "total_residual_train = 0.0 #calculating ode residuals\n",
    "total_residual_val = 0.0\n",
    "\n",
    "for epoch in range(no_epochs):\n",
    "    model.train() #for setting the model in training mode\n",
    "    \n",
    "    #getting time\n",
    "    time = train_data_tensor[:,:1]\n",
    "    \n",
    "    y_train = train_data_tensor[:,1:]\n",
    "    time = time.clone().detach().requires_grad_(True) #so model will predict based on differentiabe time\n",
    "    \n",
    "    opt.zero_grad()  #apply zero grad condition\n",
    "    pred_test = model(time)  #predictions\n",
    "    mse_loss = loss_fn(pred_test,y_train) #mse loss\n",
    "    ode_loss,mean_residual_train = ode_loss_fn(pred_test,time,m_1,m_2,G) #ode loss function\n",
    "    total_residual_train += mean_residual_train\n",
    "    total_loss = 0.6*ode_loss+ 0.4*mse_loss  #total weighted loss\n",
    "    total_loss.backward()  #backward step\n",
    "    opt.step() #used for adjusting weights \n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    #gettig time\n",
    "    time_val = val_data_tensor[:,:1]\n",
    "    y_val = val_data_tensor[:,1:]\n",
    "    \n",
    "    time_val = time_val.clone().detach().requires_grad_(True) #so model will predict based on differentiabe time\n",
    "    \n",
    "    val_pred = model(time_val)\n",
    "    val_mse_loss = loss_fn(val_pred,y_val) #mse loss\n",
    "    val_ode_loss,mean_residual_val = ode_loss_fn(val_pred,time_val,m_1,m_2,G) #ode loss and mean residuals\n",
    "    total_residual_val += mean_residual_val\n",
    "    val_total_loss = 0.6*val_ode_loss+0.4*val_mse_loss #total weighted loss\n",
    "    #print statement\n",
    "    if (epoch+1)%10 == 0 or epoch == 0 :\n",
    "        print(\"Epoch [{}/{}], Loss : {:.4f}\".format(epoch+1,no_epochs,val_total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2c57748-1953-4d80-9760-8f2831d6f759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Residual across train data: 1.4273813962936401\n",
      "Mean Residual across val data: 3.7749547958374023\n"
     ]
    }
   ],
   "source": [
    "#mean ode residuals\n",
    "train_residual = total_residual_train/len(train_data_tensor)\n",
    "val_residual = total_residual_val/len(val_data_tensor)\n",
    "#print statement\n",
    "print(\"Mean Residual across train data: {}\".format(train_residual))\n",
    "print(\"Mean Residual across val data: {}\".format(val_residual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bea27e7a-05d4-452f-80b3-d09bd788efc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mae for test data is : 12.852261543273926\n",
      "Residual across test data: 7.551054295618087e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "total_residual_test = 0.0\n",
    "model.eval() #switch to evaluation mode\n",
    "\n",
    "#getting time\n",
    "time_test = test_data_tensor[:,:1]\n",
    "y_test = test_data_tensor[:,1:]\n",
    "time_test = time_test.clone().detach().requires_grad_(True)\n",
    "y_test_pred = model(time_test) #predictions\n",
    "ode_loss,mean_residual_test = ode_loss_fn(y_test_pred,time_test,m_1,m_2,G) #ode loss function\n",
    "total_residual_test += mean_residual_test \n",
    "\n",
    "mae = mean_absolute_error(y_test.detach().numpy(),y_test_pred.detach().numpy()) #mae\n",
    "\n",
    "#print step\n",
    "print(\"Mae for test data is : {}\".format(mae))\n",
    "print(\"Residual across test data: {}\".format(total_residual_test/len(test_data_tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "923be1cd-92e1-40c4-96c5-77f604ece4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of final test case is: 16.249011993435253\n"
     ]
    }
   ],
   "source": [
    "#find coordinates at t\n",
    "result = get_coordinates_at_t(t, y0, G, m_1, m_2)\n",
    "x1, v1, x2, v2 = result[0:2], result[2:4], result[4:6], result[6:8]\n",
    "#storing x1 and x2 in single numpy array\n",
    "final_test_case_y = np.concatenate([x1,x2])\n",
    "\n",
    "#predicting coordinates at time t\n",
    "final_test_case_x_tensor = torch.tensor([t])\n",
    "\n",
    "model.eval() #switch to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    final_test_case_y_pred_tensor = model(final_test_case_x_tensor) #predictions\n",
    "\n",
    "#calculating mae for this\n",
    "mae_final = mean_absolute_error(final_test_case_y_pred_tensor.numpy(), final_test_case_y) #calculate to numpy before\n",
    "\n",
    "#print statement\n",
    "print(\"MAE of final test case is: {}\".format(mae_final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
